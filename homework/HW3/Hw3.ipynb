{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downloaded the data using the following shell script and the header\n",
    "    :\n",
    "\n",
    "    getData()\n",
    "    {\n",
    "        CSV=\"pima-indians-diabetes.csv\"\n",
    "        wget -O ${CSV} https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\n",
    "        wget -O description https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.names\n",
    "        HDR=\"pregnantNo,plasmaGlucose,bloodPressure,triceps,serumInsulin,bodyMass,diabetesPedigree,age,target\"\n",
    "        sed -i '1i\\'\"${HDR}\" ${CSV}\n",
    "    }\n",
    "\n",
    "    getData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All the imports required for HW3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from bokeh.plotting import figure, output_file, show, vplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the csv file\n",
    "df = pd.read_csv(\"pima-indians-diabetes.csv\", header = 0).dropna()\n",
    "\n",
    "to_predict = \"target\"\n",
    "\n",
    "# since I did not have an hypothosis I chose all the fields\n",
    "features = ['pregnantNo', 'plasmaGlucose', 'bloodPressure', 'triceps', 'serumInsulin', \\\n",
    "                'bodyMass', 'diabetesPedigree', 'age']\n",
    "\n",
    "# feature Data\n",
    "data = df[features]\n",
    "\n",
    "# label data\n",
    "label = df[to_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of folds\n",
    "folds = 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tried couple of my own cross validate functions and finally took Justin's function.\n",
    "\n",
    "def cross_validate_df(data, label, kfold, model):\n",
    "    positions = data.index.values\n",
    "    np.random.shuffle(positions)\n",
    "    cv_score = 0\n",
    "\n",
    "    for i in range(kfold):\n",
    "        pos_var = len(data) / kfold\n",
    "\n",
    "        test_slice = positions[i * pos_var: (i + 1) * pos_var]\n",
    "\n",
    "        train_1 = positions[ : i * pos_var]\n",
    "        train_2 = positions[ (i + 1) * pos_var : ]\n",
    "\n",
    "        train_slice = np.concatenate([train_1, train_2])\n",
    "\n",
    "        model.fit(data.loc[train_slice], label.loc[train_slice])\n",
    "        k_score = model.score(data.loc[test_slice], label.loc[test_slice]) * 100;\n",
    "\n",
    "        cv_score += k_score\n",
    "\n",
    "    return cv_score / kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NaiveBayes():\n",
    "    # create a model for NaiveBayes\n",
    "    model = MultinomialNB()\n",
    "\n",
    "    # cross validate data\n",
    "    print cross_validate_df(data, label, folds, model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knnNeighbor():\n",
    "    # number of neighbors\n",
    "    neighbors = 50\n",
    "\n",
    "    nn = range(2, neighbors)\n",
    "\n",
    "    #scoreArray\n",
    "    scoreArray = []\n",
    "\n",
    "    # for each neighbors\n",
    "    for n in nn:\n",
    "        # create a model with n neighbors\n",
    "        model = KNeighborsClassifier(n)\n",
    "\n",
    "        scoreArray.append(cross_validate_df(data, label, folds, model))\n",
    "\n",
    "    plot = figure(title = \"Neighbors vs Score\")\n",
    "    plot.line(nn, scoreArray)\n",
    "    plot.xaxis.axis_label = \"Neighbors\"\n",
    "    plot.yaxis.axis_label = \"Score\"\n",
    "\n",
    "    output_file(\"diabetes.html\", title = \"Neighbors vs Score\")\n",
    "\n",
    "    p = vplot(plot)\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# execute the KnnNeighbor\n",
    "knnNeighbor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.1307189542\n"
     ]
    }
   ],
   "source": [
    "# execute NaiveBayes\n",
    "NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the given Data set KnnNeighbor around 20 neighbors seems to give about 78% accuracy \n",
    "#     and NaiveBayes gives about 60%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
