{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.learning_curve import learning_curve\n",
    "\n",
    "from bokeh.models import Range1d\n",
    "from bokeh.charts import HeatMap\n",
    "from bokeh.palettes import RdYlBu9 as palette\n",
    "from bokeh.plotting import figure, show, output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot html file\n",
    "output_file(\"hw05.html\", title = \"hw05\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read data to pandas data frame\n",
    "# convert non mumeric values to nan using convert_objects and drop na's using dropna\n",
    "# field Bare_Nuclei had \"?\" values\n",
    "cf = pd.read_csv(\"cancer_uci.csv\", header = 0).convert_objects(convert_numeric = True).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to plot roc\n",
    "def plot_roc_curve(target_test, target_predicted_proba, kernel):\n",
    "    fpr, tpr, thresholds = roc_curve(target_test, target_predicted_proba[:, 1])\n",
    "\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    p = figure(title = \"ROC (%s)\" % (kernel))\n",
    "\n",
    "    # Plot ROC curve\n",
    "    p.line(x = fpr, y = tpr, legend = \"ROC curve (area = %0.3f)\" % roc_auc)\n",
    "    p.x_range = Range1d(0, 1)\n",
    "    p.y_range = Range1d(0, 1)\n",
    "    p.xaxis.axis_label = \"False Positive Rate or (1 - Specifity)\"\n",
    "    p.yaxis.axis_label = \"True Positive Rate or (Sensitivity)\"\n",
    "    p.legend.orientation = \"bottom_right\"\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function for SVM\n",
    "def svm(kernel, balance):\n",
    "    print \"For %s kernel\" % (kernel)\n",
    "\n",
    "    if balance:\n",
    "        # Only Malignant\n",
    "        mf = cf[cf['Class'] == \"Malignant\"]\n",
    "\n",
    "        # Only Benign\n",
    "        bf = cf[cf['Class'] == \"Benign\"]\n",
    "\n",
    "        # The ratio between Malignant and Beign is around 34%\n",
    "        # Balance Benign by sampling out to the len of Maliganat to get 50/50 ratio\n",
    "        bf_samp = bf.sample(len(mf))\n",
    "\n",
    "        if False:\n",
    "            print \"%4d %4d %4d %4d %4d %.2f\" % (len(cf), len(mf), len(bf), len(mf) + len(bf),\n",
    "                    len(bf_samp), len(mf) * 100.0 / len(cf))\n",
    "\n",
    "        # create a balanced data frame using sampled data\n",
    "        new_cf = pd.concat([bf_samp, mf])\n",
    "    else:\n",
    "        # No balancing\n",
    "        new_cf = cf\n",
    "\n",
    "    # convert string to boolean (for class)\n",
    "    target_cf = pd.DataFrame(new_cf['Class'].map({'Benign' : 0, 'Malignant' : 1}))\n",
    "\n",
    "    feature_names = new_cf.columns[2:-1]\n",
    "\n",
    "    # Get y\n",
    "    y = target_cf.Class\n",
    "\n",
    "    # Get X (features)\n",
    "    X = pd.DataFrame(new_cf, columns = feature_names)\n",
    "\n",
    "    # split train and test\n",
    "    index = range(0, len(X))\n",
    "    np.random.shuffle(index)\n",
    "    train = index[ : len(X) * 3 / 5]\n",
    "    test = index[len(X) * 3 / 5 : ]\n",
    "\n",
    "    model = SVC(kernel = kernel, probability = True, C = 1).fit(X.iloc[train], y.iloc[train])\n",
    "    results = model.predict(X.iloc[test])\n",
    "\n",
    "    print \"Classification report\"\n",
    "    print classification_report(y.iloc[test], results)\n",
    "\n",
    "    cm = confusion_matrix(y.iloc[test], results)\n",
    "    print \"Confusion matrix\"\n",
    "    print cm\n",
    "\n",
    "    xyvalues = {}\n",
    "    xyvalues['Predicted False'] = {'Actual False' : cm[0, 0], 'Actual True' : cm[0, 1]}\n",
    "    xyvalues['Predicted True'] = {'Actual False' : cm[1, 0], 'Actual True' : cm[1, 1]}\n",
    "\n",
    "    if False:\n",
    "        hm = HeatMap(xyvalues, title='Confusion Matrix', palette = palette)\n",
    "        show(hm)\n",
    "\n",
    "    print cm, '\\n'\n",
    "    print \"Precision:\", float(cm[1, 1]) / (cm[0, 1] + cm[1, 1])\n",
    "    print \"Recall:   \", float(cm[1, 1]) / (cm[1, 0] + cm[1, 1]), '\\n'  \n",
    "    \n",
    "    if False:\n",
    "        target_predicted_proba = model.predict_proba(X.iloc[test])\n",
    "        plot_roc_curve(y.iloc[test], target_predicted_proba,\n",
    "                \"Balance: \" + str(balance) + \", SVM: \" + kernel)\n",
    "\n",
    "    # sklearn learning curve function to generate scores\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, X.iloc[index], y.iloc[index], cv = 5)\n",
    "\n",
    "    print 'Training Score:', train_scores.mean(axis = 1)\n",
    "    print '\\n'\n",
    "    print 'Test Score:', test_scores.mean(axis = 1)\n",
    "\n",
    "    if True:\n",
    "        # Create our base figure\n",
    "        p = figure(title = 'Learning Curve', y_range = (0, 1))\n",
    "\n",
    "        # Create our Training score line\n",
    "        p.line(x = train_sizes, y = train_scores.mean(axis = 1), color = 'red',\n",
    "                legend = \"Training Scores\")\n",
    "\n",
    "        # Create our Testing score line\n",
    "        p.line(x = train_sizes, y = test_scores.mean(axis = 1), color = 'blue',\n",
    "                legend = \"Test Scores\")\n",
    "\n",
    "        # Move our legend around\n",
    "        p.legend.orientation = \"bottom_right\"\n",
    "\n",
    "        # Render the plot!!\n",
    "        show(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dtree():\n",
    "    # convert string to boolean (for class)\n",
    "    target_cf = pd.DataFrame(cf['Class'].map({'Benign' : 0, 'Malignant' : 1}))\n",
    "\n",
    "    feature_names = cf.columns[2:-1]\n",
    "\n",
    "    features = cf[feature_names]\n",
    "    target = target_cf.Class\n",
    "\n",
    "    model = DecisionTreeClassifier(random_state = 0)\n",
    "    mf = model.fit(features, target)\n",
    "\n",
    "    print pd.crosstab(target, model.predict(features))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, random_state = 0)\n",
    "    model = DecisionTreeClassifier(random_state = 0)\n",
    "    mf = model.fit(X_train, y_train)\n",
    "\n",
    "    results = model.predict(X_test)\n",
    "    print pd.crosstab(y_test, results)\n",
    "\n",
    "    print \"Classification report\"\n",
    "    print classification_report(y_test, results)\n",
    "\n",
    "    cm = confusion_matrix(y_test, results)\n",
    "    print \"Confusion matrix\"\n",
    "    print cm\n",
    "\n",
    "    xyvalues = {}\n",
    "    xyvalues['Predicted False'] = {'Actual False' : cm[0, 0], 'Actual True' : cm[0, 1]}\n",
    "    xyvalues['Predicted True'] = {'Actual False' : cm[1, 0], 'Actual True' : cm[1, 1]}\n",
    "\n",
    "    if False:\n",
    "        hm = HeatMap(xyvalues, title='Confusion Matrix', palette = palette)\n",
    "        show(hm)\n",
    "\n",
    "    print cm, '\\n'\n",
    "    print \"Precision:\", float(cm[1, 1]) / (cm[0, 1] + cm[1, 1])\n",
    "    print \"Recall:   \", float(cm[1, 1]) / (cm[1, 0] + cm[1, 1]), '\\n'\n",
    "\n",
    "    target_predicted_proba = model.predict_proba(X_test)\n",
    "\n",
    "    if True:\n",
    "        plot_roc_curve(y_test, target_predicted_proba, \"Dtree\")\n",
    "\n",
    "    # create new dataframes with features, target, results\n",
    "    cf_features = pd.DataFrame(X_test, columns = feature_names)\n",
    "    cf_target = pd.DataFrame(y_test, columns = ['Class (acutal)'])\n",
    "    cf_results = pd.DataFrame(results, columns = ['Class (predicted)'])\n",
    "\n",
    "    # join the features, actual and predicted into one dataframe\n",
    "    ncf = cf_features.join(cf_target).join(cf_results)\n",
    "\n",
    "    cf_errors = ncf[(ncf['Class (acutal)'] != ncf['Class (predicted)'])]\n",
    "    #print cf_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For linear kernel\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98        86\n",
      "          1       1.00      0.97      0.99       106\n",
      "\n",
      "avg / total       0.98      0.98      0.98       192\n",
      "\n",
      "Confusion matrix\n",
      "[[ 86   0]\n",
      " [  3 103]]\n",
      "[[ 86   0]\n",
      " [  3 103]] \n",
      "\n",
      "Precision: 1.0\n",
      "Recall:    0.971698113208 \n",
      "\n",
      "Training Score: [ 1.          0.99677419  0.97809524  0.97567568  0.97905759]\n",
      "\n",
      "\n",
      "Test Score: [ 0.92907801  0.94787234  0.95828901  0.97083333  0.96870567]\n"
     ]
    }
   ],
   "source": [
    "svm(\"linear\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For linear kernel\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.96      0.97       184\n",
      "          1       0.93      0.97      0.95        90\n",
      "\n",
      "avg / total       0.96      0.96      0.96       274\n",
      "\n",
      "Confusion matrix\n",
      "[[177   7]\n",
      " [  3  87]]\n",
      "[[177   7]\n",
      " [  3  87]] \n",
      "\n",
      "Precision: 0.925531914894\n",
      "Recall:    0.966666666667 \n",
      "\n",
      "Training Score: [ 0.9962963   0.98305085  0.97666667  0.97399527  0.97289377]\n",
      "\n",
      "\n",
      "Test Score: [ 0.95461476  0.96341714  0.9561395   0.96193566  0.96487699]\n"
     ]
    }
   ],
   "source": [
    "svm(\"linear\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rbf kernel\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95        98\n",
      "          1       0.91      1.00      0.95        94\n",
      "\n",
      "avg / total       0.96      0.95      0.95       192\n",
      "\n",
      "Confusion matrix\n",
      "[[89  9]\n",
      " [ 0 94]]\n",
      "[[89  9]\n",
      " [ 0 94]] \n",
      "\n",
      "Precision: 0.912621359223\n",
      "Recall:    1.0 \n",
      "\n",
      "Training Score: [ 1.          1.          0.99714286  0.99594595  0.99528796]\n",
      "\n",
      "\n",
      "Test Score: [ 0.94964539  0.95172872  0.94964539  0.95177305  0.95598404]\n"
     ]
    }
   ],
   "source": [
    "svm(\"rbf\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rbf kernel\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98       185\n",
      "          1       0.94      1.00      0.97        89\n",
      "\n",
      "avg / total       0.98      0.98      0.98       274\n",
      "\n",
      "Confusion matrix\n",
      "[[179   6]\n",
      " [  0  89]]\n",
      "[[179   6]\n",
      " [  0  89]] \n",
      "\n",
      "Precision: 0.936842105263\n",
      "Recall:    1.0 \n",
      "\n",
      "Training Score: [ 1.          1.          0.99733333  0.99716312  0.9970696 ]\n",
      "\n",
      "\n",
      "Test Score: [ 0.93561503  0.95171668  0.95759935  0.95908083  0.95908083]\n"
     ]
    }
   ],
   "source": [
    "svm(\"rbf\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0    0    1\n",
      "Class          \n",
      "0      444    0\n",
      "1        0  239\n",
      "col_0    0   1\n",
      "Class         \n",
      "0      105   2\n",
      "1        7  57\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96       107\n",
      "          1       0.97      0.89      0.93        64\n",
      "\n",
      "avg / total       0.95      0.95      0.95       171\n",
      "\n",
      "Confusion matrix\n",
      "[[105   2]\n",
      " [  7  57]]\n",
      "[[105   2]\n",
      " [  7  57]] \n",
      "\n",
      "Precision: 0.966101694915\n",
      "Recall:    0.890625 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtree()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
